{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Step: Load in packages"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext lab_black"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from skimpy import clean_columns\n",
        "import pandas as pd\n",
        "from pyprojroot import here\n",
        "import os\n",
        "import mlflow\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from skopt import BayesSearchCV\n",
        "from joblib import dump, load\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import roc_auc_score, balanced_accuracy_score, f1_score\n",
        "from sklearn.metrics import plot_precision_recall_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "from analysis.fun_class_positive_predictions import fun_class_positive_predictions\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from analysis.fun_classifer_xgboost_bayes import fun_classifer_xgboost_bayes\n",
        "from analysis.fun_imbalanced_threshold_locator import fun_imbalanced_threshold_locator\n",
        "from analysis.fun_class_accuracy_calcaulator import fun_class_accuracy_calcaulator\n",
        "from analysis.fun_drop_high_correlation import fun_drop_high_correlation\n",
        "import lightgbm as lgb\n",
        "from analysis.fun_imbalanced_threshold import fun_imbalanced_threshold\n",
        "from analysis.fun_class_predictions_id import fun_class_predictions_id\n",
        "\n",
        "path_data = here(\"./data\")\n",
        "os.chdir(path_data)\n",
        "data_trading_analysis = pd.read_parquet(\"data_trading_good_features.parquet\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669989426201
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step: Add an id, because you are lazy want to use your pre-built function"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_trading_analysis_id = data_trading_analysis.reset_index()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669989455828
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step: Remove highly correlated features"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_trading_analysis_low_corr = fun_drop_high_correlation(\n",
        "    data=data_trading_analysis_id,\n",
        "    outcome=[\"result\"],\n",
        ")\n",
        "\n",
        "data_trading_analysis_low_corr.to_parquet(\"data_trading_analysis_low_corr.parquet\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669989465666
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step: Split test and training"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = data_trading_analysis_low_corr.drop(columns=[\"result\"])\n",
        "y = data_trading_analysis_low_corr[\"result\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669989468834
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step: Get the imbalance measurement"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from analysis.fun_scale_pos_weight import fun_scale_pos_weight\n",
        "\n",
        "scale_pos_weight = fun_scale_pos_weight(y_train=y_train, outcome=\"result\")\n",
        "scale_pos_weight"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669989471286
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step: Run ML "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_xgb = fun_classifer_xgboost_bayes(\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    x_train=x_train,\n",
        "    y_train=y_train,\n",
        "    n_splits=3,\n",
        "    n_repeats=3,\n",
        "    id_var=\"index\",\n",
        ")\n",
        "\n",
        "path_outputs = here(\"./outputs\")\n",
        "os.chdir(path_outputs)\n",
        "joblib.dump(results_xgb, \"results_xgb.jlib\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669989591028
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step: Get predictions for all data and just training"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_prob_all = fun_class_positive_predictions(\n",
        "    model=results_xgb,\n",
        "    x_train_or_test=data_trading_analysis_low_corr,\n",
        "    id_vars=[\"index\", \"result\"],\n",
        ")\n",
        "\n",
        "data_prob_train = fun_class_positive_predictions(\n",
        "    model=results_xgb,\n",
        "    x_train_or_test=x_train,\n",
        "    id_vars=[\"index\"],\n",
        ")\n",
        "\n",
        "data_prob_test = fun_class_positive_predictions(\n",
        "    model=results_xgb,\n",
        "    x_train_or_test=x_test,\n",
        "    id_vars=[\"index\"],\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669989646066
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step: Get threshold for imbalanced data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669989971215
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fun_imbalanced_threshold_balanced_accuracy(y_train, y_train_probability):\n",
        "    \"\"\"Looks the point that maximizes the recall and precision among the predicted probability to identify better thresholds for\n",
        "    imbalanced data using the training data to avoid data leakage.  Only returns the threshold\n",
        "\n",
        "    Args:\n",
        "        y_train (int): y_test from a test train split\n",
        "        y_train_probability (int): Predicted probability using training data.\n",
        "\n",
        "\n",
        "    Returns:\n",
        "        array: An array of updated predicted values (i.e., 1's and 0's) based on the threshold.  And the threshold value\n",
        "    \"\"\"\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(y_train, y_train_probability, pos_label=1)\n",
        "    balanced_accuracy = (fpr + tpr) / 2\n",
        "\n",
        "    # locate the index of the largest f score\n",
        "    ix = np.argmax(balanced_accuracy)\n",
        "    threshold = thresholds[ix]\n",
        "    return threshold"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669990235210
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = metrics.roc_curve(y_train, data_prob_train, pos_label=1)\n",
        "balanced_accuracy = (fpr + tpr) / 2"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669990264463
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = fun_imbalanced_threshold_balanced_accuracy(\n",
        "    y_train=y_train, y_train_probability=data_prob_train\n",
        ")\n",
        "threshold"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669990241100
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step: Get classification for all data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_trading_classification = fun_class_predictions_id(\n",
        "    data_id=data_trading_analysis_low_corr[\"index\"],\n",
        "    outcome_probability=data_prob_all,\n",
        "    threshold=0.5,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669990514490
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step: Get predicted y for training"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fun_imbalanced_balanced_accuracy_threshold_locator(y_train, threshold):\n",
        "    threshold = pd.Series(np.arange(0.01, 1, 0.01))\n",
        "    data_best_accuracy_out = []\n",
        "    for x in range(len(threshold)):\n",
        "        y_threshold = np.where(y_train > threshold[x], 1, 0)\n",
        "        results_balanced_accuracy = balanced_accuracy_score(\n",
        "            y_train, y_threshold, adjusted=True\n",
        "        )\n",
        "        data_best_accuracy_out.append(results_balanced_accuracy)\n",
        "    threshold_pd = pd.DataFrame(pd.concat([threshold])).rename(columns={0: \"threshold\"})\n",
        "    data_best_accuracy_out_pd = pd.DataFrame(data_best_accuracy_out).rename(\n",
        "        columns={0: \"balanced_accuracy\"}\n",
        "    )\n",
        "    data_threshold_accuracy = pd.concat(\n",
        "        [threshold_pd, data_best_accuracy_out_pd], axis=1\n",
        "    )\n",
        "    data_threshold_value = data_threshold_accuracy[\n",
        "        data_threshold_accuracy.balanced_accuracy\n",
        "        == data_threshold_accuracy.balanced_accuracy.max()\n",
        "    ]\n",
        "    data_threshold_value = data_threshold_value[\"threshold\"]\n",
        "    return data_threshold_value"
      ],
      "outputs": [],
      "execution_count": 63,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669993668824
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = pd.Series(np.arange(0.01, 1, 0.01))\n",
        "data_best_accuracy_out = []\n",
        "for x in range(len(threshold)):\n",
        "    y_threshold = np.where(data_prob_train > threshold[x], 1, 0)\n",
        "    results_balanced_accuracy = balanced_accuracy_score(\n",
        "        y_train, y_threshold, adjusted=True\n",
        "    )\n",
        "    data_best_accuracy_out.append(results_balanced_accuracy)\n",
        "threshold_pd = pd.DataFrame(pd.concat([threshold])).rename(columns={0: \"threshold\"})\n",
        "data_best_accuracy_out_pd = pd.DataFrame(data_best_accuracy_out).rename(\n",
        "    columns={0: \"balanced_accuracy\"}\n",
        ")\n",
        "data_threshold_accuracy = pd.concat([threshold_pd, data_best_accuracy_out_pd], axis=1)"
      ],
      "outputs": [],
      "execution_count": 43,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669991279163
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold_pd = pd.DataFrame(pd.concat([threshold])).rename(columns={0: \"threshold\"})\n",
        "data_best_accuracy_out_pd = pd.DataFrame(data_best_accuracy_out).rename(\n",
        "    columns={0: \"balanced_accuracy\"}\n",
        ")\n",
        "data_threshold_accuracy = pd.concat([threshold_pd, data_best_accuracy_out_pd], axis=1)\n",
        "data_threshold_accuracy"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 58,
          "data": {
            "text/plain": "    threshold  balanced_accuracy\n0        0.01           0.000000\n1        0.02           0.002094\n2        0.03           0.009424\n3        0.04           0.015707\n4        0.05           0.034555\n..        ...                ...\n94       0.95           0.134927\n95       0.96           0.094024\n96       0.97           0.054980\n97       0.98           0.026826\n98       0.99           0.004781\n\n[99 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>threshold</th>\n      <th>balanced_accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.01</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.02</td>\n      <td>0.002094</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.03</td>\n      <td>0.009424</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.04</td>\n      <td>0.015707</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.05</td>\n      <td>0.034555</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>0.95</td>\n      <td>0.134927</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>0.96</td>\n      <td>0.094024</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>0.97</td>\n      <td>0.054980</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>0.98</td>\n      <td>0.026826</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>0.99</td>\n      <td>0.004781</td>\n    </tr>\n  </tbody>\n</table>\n<p>99 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 58,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669993298434
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_threshold_value = data_threshold_accuracy[\n",
        "    data_threshold_accuracy.balanced_accuracy\n",
        "    == data_threshold_accuracy.balanced_accuracy.max()\n",
        "]\n",
        "data_threshold_value = data_threshold_value[\"threshold\"]\n",
        "data_threshold_value"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 62,
          "data": {
            "text/plain": "49    0.5\nName: threshold, dtype: float64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 62,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669993576707
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted = fun_imbalanced_threshold_locator(\n",
        "    y_train=y_train,\n",
        "    y_train_probability=data_prob_train,\n",
        "    y_test_probability=data_prob_test,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669989653563
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step: Get accuracy"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_accuracy = fun_class_accuracy_calcaulator(\n",
        "    y_test=y_test, y_predicted=y_predicted\n",
        ")\n",
        "results_accuracy"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [1180, 4720]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mfun_class_accuracy_calcaulator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_predicted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_predicted\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m results_accuracy\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/analysis/fun_class_accuracy_calcaulator.py:16\u001b[0m, in \u001b[0;36mfun_class_accuracy_calcaulator\u001b[0;34m(y_test, y_predicted)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun_class_accuracy_calcaulator\u001b[39m(y_test, y_predicted):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124;03m\"\"\"Calculates balanced accuracy, f1 and roc_auc clasification metrics with y_test and y_predicted.  Produces both a DataFrame and a dictionary.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m        DataFrame: See summary\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     results_balanced_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mbalanced_accuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_predicted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjusted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     results_roc_auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, y_predicted)\n\u001b[1;32m     18\u001b[0m     results_f1_score \u001b[38;5;241m=\u001b[39m f1_score(y_test, y_predicted)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1855\u001b[0m, in \u001b[0;36mbalanced_accuracy_score\u001b[0;34m(y_true, y_pred, sample_weight, adjusted)\u001b[0m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbalanced_accuracy_score\u001b[39m(y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1794\u001b[0m                             adjusted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the balanced accuracy\u001b[39;00m\n\u001b[1;32m   1796\u001b[0m \n\u001b[1;32m   1797\u001b[0m \u001b[38;5;124;03m    The balanced accuracy in binary and multiclass classification problems to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1853\u001b[0m \n\u001b[1;32m   1854\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1855\u001b[0m     C \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1856\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(divide\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1857\u001b[0m         per_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdiag(C) \u001b[38;5;241m/\u001b[39m C\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:268\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfusion_matrix\u001b[39m(y_true, y_pred, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    197\u001b[0m                      normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    266\u001b[0m \n\u001b[1;32m    267\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:80\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true)\n\u001b[1;32m     82\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/sklearn/utils/validation.py:211\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    209\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    212\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths])\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1180, 4720]"
          ]
        }
      ],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669990678795
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}